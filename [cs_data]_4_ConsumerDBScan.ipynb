{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rjsfrbU6kV8m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26b81677-8738-4060-f30a-7cb1ff907f64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# 코랩에 구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "import warnings\n",
        "# warnings.filterwarnings(action = \"ignore\")\n",
        "\n",
        "# 데이터 처리 모듈\n",
        "import pandas as pd\n",
        "import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 멀티프로세싱\n",
        "import multiprocessing as mp\n",
        "from multiprocessing import Pool\n",
        "\n",
        "# 척도 변환 모듈(표준화, 정규화, 로버스트 정규화, 원핫인코딩(범주형에서 더미변수로 변환) 등)\n",
        "from sklearn.preprocessing import *\n",
        "\n",
        "# 결측값 관측 모듈\n",
        "import missingno as msno\n",
        "\n",
        "# 시각화 모듈\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "import seaborn as sns\n",
        "from matplotlib.ticker import ScalarFormatter\n",
        "\n",
        "# 배열, 행렬 연산 모듈\n",
        "import numpy as np\n",
        "\n",
        "# 데이터 분할 모듈(훈련용 / 검증용 / 시험용)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 통계적 가설검정 및 계량화 모듈\n",
        "# https://youtu.be/FtWEZw3kUho\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.tsa.api as smt\n",
        "from scipy.interpolate import UnivariateSpline\n",
        "\n",
        "# 타입 어노테이션 모듈\n",
        "from typing import *\n",
        "\n",
        "# 시간 관련 모듈\n",
        "from tqdm import tqdm\n",
        "from time import strptime, sleep\n",
        "\n",
        "# 웹크롤링 / 스크래핑 관련 모듈\n",
        "import requests\n",
        "import io\n",
        "import zipfile\n",
        "from bs4 import BeautifulSoup\n",
        "from xml.etree import ElementTree as ET\n",
        "\n",
        "# 결측값 대체 및 특징 추출\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.decomposition import PCA, SparsePCA\n",
        "\n",
        "# 연관규칙 분석 실행 모듈\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "import networkx as nx\n",
        "\n",
        "# 한글폰트 설정\n",
        "import matplotlib\n",
        "import matplotlib.font_manager as fm\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "from pathlib import Path\n",
        "import matplotlib.patches as mpatches"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 주식종목 데이터 로드 모듈\n",
        "!pip install pykrx\n",
        "from pykrx import stock\n",
        "!pip install finance-datareader --upgrade\n",
        "import FinanceDataReader as fdr"
      ],
      "metadata": {
        "id": "xt3Eqf0umMEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IndexDatawithEventMoment():\n",
        "\n",
        "  def __init__(self, file_path: str, DROP_COLUMN_LIST: List, SUBSET = None):\n",
        "\n",
        "    self.INDEX_NEWS_DATA = pd.read_csv(file_path, index_col = False, na_values = \"NaN\")\n",
        "      # [file_path] \"/content/drive/MyDrive/AfterLearnerProject/DataArchive/merge_derivative_news_data.csv\"\n",
        "      # [INDEX_PRINCIPAL_COMPONENT_x] 시계열 전처리한 5개 주가지수선형결합 제1주성분\n",
        "      # [INDEX_PRINCIPAL_COMPONENT_y] 시계열 전처리한 5개 주가지수선형결합 제1주성분의 단위변동률\n",
        "    self.INDEX_NEWS_DROPNA = self.INDEX_NEWS_DATA.dropna(subset = DROP_COLUMN_LIST)\n",
        "      # msno.dendrogram()\n",
        "    self.SUBSET = SUBSET\n",
        "\n",
        "\n",
        "  def compareEventDatetimewithNewsImportanceScore(self):\n",
        "    # improtance와 특이 지점을 비교하기 위해 importance값 상위 20개 추출(특이지점과 흡사)\n",
        "    display( self.INDEX_NEWS_DATA.sort_values(\n",
        "        by = \"IMPORTANCE\", ascending = False).head(20)[[\"IMPORTANCE\", \"YYYYMMDD\", \"TAG_LIST\"]] )\n",
        "\n",
        "\n",
        "  def removeBlank(self):\n",
        "    import re\n",
        "    self.INDEX_NEWS_DROPNA[\"TAG_LIST\"] = self.INDEX_NEWS_DROPNA[\"TAG_LIST\"].apply(\n",
        "        lambda tag: re.sub(\" \", \"\", tag))\n",
        "    self.INDEX_NEWS_DROPNA[\"ITEM_NAME\"] = self.INDEX_NEWS_DROPNA[\"ITEM_NAME\"].apply(lambda tag: re.sub(\" \", \"\", tag))\n",
        "      # \"\\s{0,}\"\n",
        "      # re.sub(\" +\", \"\" , string)\n",
        "      # \" \".join(string.split())\n",
        "\n",
        "\n",
        "  def mutateNewColumn(self):\n",
        "    self.INDEX_NEWS_DROPNA[\"CHANGE_CATEGORY\"] = (\n",
        "        self.INDEX_NEWS_DROPNA[\"STABLE_or_DRAMATIC\"].astype(str) + \"_\" + self.INDEX_NEWS_DROPNA[\"SIGN_CHANGE\"].astype(str))\n",
        "    self.INDEX_NEWS_DROPNA[\"TAG_SPLIT\"] = self.INDEX_NEWS_DROPNA.TAG_LIST.str.split(\"|\")\n",
        "    self.INDEX_NEWS_DROPNA[\"ITEM_SPLIT\"] = self.INDEX_NEWS_DROPNA.ITEM_NAME.str.split(\"|\")\n",
        "    print( \"\\n\", Counter(self.INDEX_NEWS_DROPNA[\"CHANGE_CATEGORY\"]) , \"\\n\", Counter(self.INDEX_NEWS_DROPNA[\"YYYYMMDD\"]) )\n",
        "    return self.INDEX_NEWS_DROPNA\n",
        "\n",
        "\n",
        "  def makeSubDataset_loadData(self, date_column: str, date_time: str):\n",
        "\n",
        "    INDEX_NEWS_DATETIME = self.INDEX_NEWS_DROPNA[ self.INDEX_NEWS_DROPNA[date_column] == date_time ]\n",
        "    self.SUBSET = INDEX_NEWS_DATETIME[[\"CHANGE_CATEGORY\", \"SUBCATEGORY\"]].values\n",
        "      # [column] \"ITEM_NAME\", \"SUBCATEGORY\"\n",
        "    return self.SUBSET, INDEX_NEWS_DATETIME\n",
        "      # [date_column] YYYYMMDD"
      ],
      "metadata": {
        "id": "r4tuSVBDauwR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae157d9b-e77f-4b5c-d436-721daad77847"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mIiDJPep_5Q"
      },
      "outputs": [],
      "source": [
        "MarketIndexObject = IndexDatawithEventMoment(\n",
        "    file_path = \"/content/drive/MyDrive/AfterLearnerProject/DataArchive/merge_derivative_news_data.csv\",\n",
        "    DROP_COLUMN_LIST = [\"TAG_LIST\", \"ITEM_NAME\"]\n",
        ")\n",
        "\n",
        "MarketIndexObject.compareEventDatetimewithNewsImportanceScore()\n",
        "MarketIndexObject.removeBlank()\n",
        "INDEX_NEWS_DATA = MarketIndexObject.mutateNewColumn()\n",
        "# Counter({'2023-03-15': 2918, '2023-03-10': 2152, '2023-04-12': 1858, '2023-02-01': 1687, '2023-01-31': 1621, '2023-02-02': 1565, '2023-01-26': 1376, '2023-01-25': 1294, '2023-01-27': 1062})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2023-01-25** | DRAMATIC_Not Change\n",
        "(AI)\t(인공지능) | (인공지능)\t(AI)\n",
        "\n",
        "(은행)\t(금리) | (대출)\t(금리)\n"
      ],
      "metadata": {
        "id": "Rsj75qBcjm3e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2023-01-26** | DRAMATIC_Not Change\n",
        "\n",
        "(대출)\t(금리) | (금리, 은행)\t(대출)\n",
        "\n",
        "(무인기)\t(북한)\t| (북한)\t(무인기)"
      ],
      "metadata": {
        "id": "Sg07CI5Tj1UL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2023-01-27** | DRAMATIC_Not Change\n",
        "(마스크)\t(코로나19) | (코로나19) (마스크)\n",
        "\n",
        "(전기차)\t(중국)\t| (전기차)\t(글로벌)\n",
        "\n",
        "(전기차)  (배터리)\t| (배터리)\t(전기차)"
      ],
      "metadata": {
        "id": "jiD2xO2Fj1nk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2023-01-31** | DRAMATIC_Not Change\n",
        "(반도체)\t(메모리) | (메모리)\t(반도체) | (파운드리)\t(반도체)\n",
        "\n",
        "(반도체)\t(글로벌) | (일본)\t(중국) | (코로나19)\t(중국) | (소비)\t(중국)\n",
        "\n",
        "(부동산)\t(주택)\t| (주택)\t(부동산)"
      ],
      "metadata": {
        "id": "zI3bv4kjj1MT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2023-02-01** | DRAMATIC_Sign Change\n",
        "\n",
        "(중국)\t(글로벌) | (리오프닝)\t(중국)\n",
        "\n",
        "(대출)\t(금리)\n",
        "\n",
        "(반도체)\t(메모리)"
      ],
      "metadata": {
        "id": "1FFlhKVHjwdg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2023-02-02** | DRAMATIC_Sign Change\n",
        "\n",
        "(스마트폰)\t(갤럭시) | (갤럭시)\t(스마트폰) | (카메라)\t(갤럭시) | (디지털)\t(플랫폼)\n",
        "\n",
        "(금리)\t(중앙은행) | (금융)  (금리) | (채권)\t(금리)\n",
        "\n",
        "(배터리)\t(전기차)\t|  (전기차)\t(배터리)\n",
        "\n",
        "\n",
        "\n",
        "(전기)\t(가스)"
      ],
      "metadata": {
        "id": "7ZGfF25Kj1Y2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2023-03-10** | DRAMATIC_Not Change\n",
        "\n",
        "(이머징마켓, 아시아)\t(미국) | (미국, 이머징마켓)\t(아시아) | (중국, 아시아)\t(이머징마켓)\n",
        "\n",
        "(EU, 미국) | (, 소재)\t(미국)\n",
        "\n",
        "(채권)\t(금리)"
      ],
      "metadata": {
        "id": "rItuPXOej1f4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2023-04-12** | DRAMATIC_Not Change\n",
        "(미국, 아시아)\t(이머징마켓) | (미국, 이머징마켓)\t(아시아) | (아시아, 이머징마켓)\t(미국)\n",
        "(소재)\t(미국) | (헬스케어)\t(미국)\t| (미세먼지)\t(황사)\n",
        "(중국, 이머징마켓)\t(아시아) | (EU, 아시아)\t(이머징마켓)"
      ],
      "metadata": {
        "id": "E_XCJR_8j1vI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CS_DATA**와 MARKET_INDEX_NEWS_DATA 8가지 시점별 병합"
      ],
      "metadata": {
        "id": "Fa-pbv8L9no0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 시계열 정보 : 4개월간의 자산 및 거래, 접속내역 데이터\n",
        "* 후위 표시자로 시기 구분\n",
        "* 자산내역 : 월말일 기준 데이터 제공\n",
        "\n",
        "  M1(2022.12), M2(2023.01), M3(2023.02), M4(2023.03)\n",
        "* 거래내역, 접속내역 : 월별 초순, 중순, 하순 동안의 데이터 집계내역 제공\n",
        "\n",
        "  M2_1(2023.01 초순 1 ~ 10일), M2_2(2023.01 중순 11 ~ 20일), M2_3(2023.01 하순 21 ~ 말일)을 _1, _2, _3으로 구분\n",
        "  \n",
        "* 『전략적 인출 설계와 은퇴 포트폴리오의 과학』\n"
      ],
      "metadata": {
        "id": "B2cz6MIAsJKE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.필요한 데이터 처리하는 함수 및 전처리된 데이터**"
      ],
      "metadata": {
        "id": "O6alUaG8njIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LoadData():\n",
        "\n",
        "# 클래스(로컬공간) 내부에서 cs_data, apy_itm_hist_dat, market_index_data의 값\n",
        "# 생성자를 활용하여 초기화하고 클래스 내부에 캡슐화\n",
        "  def __init__(self,\n",
        "               cs_data_path: str, apy_itm_hist_path: str):\n",
        "    # 용량이 큰 csv 파일 읽어오기(fopen - fread와 유사한 방식)\n",
        "    cs_chunk = pd.read_csv(cs_data_path, chunksize = 10**5, index_col = False, na_values = \"NaN\", encoding = \"utf-8\")\n",
        "    self.cs_data = list(cs_chunk)\n",
        "    self.apy_itm_hist_data = pd.read_csv(apy_itm_hist_path, index_col = False, na_values = \"NaN\", encoding = \"utf-8\")\n",
        "      # [BAS_YM] (19.12 ~ 23.04) 기준연월\n",
        "      # [APY_ITM] (19.12 ~ 23.04)간 공모주 청약 진행된 종목 번호\n",
        "      # [APY_FIN_YM] 이전 3년(19.12 ~ 22.11)간 마지막으로 참여한 공모주 청약연월(X)\n",
        "      # [APY_ITM_CNT] 이전 3년(19.12 ~ 22.11)간 공모주 청약에 참여한 종목 개수(X)\n",
        "\n",
        "\n",
        "# parallelDataFrame()\n",
        "# csv(쉼표로 분할된) 데이터 로드 시 병렬처리하는 메서드\n",
        "# 실제로 수행할 정도로 데이터 크기가 크지는 않고 100,000행씩 chunking하면 해결됨\n",
        "  def parallelDataFrame(self, data, function):\n",
        "    # 코어 수 확인(multiprocessing as mp)\n",
        "    mp.cpu_count()\n",
        "    # 코어 수를 전역변수 선언\n",
        "    global num_cores\n",
        "    # 코어 수만큼 입력받은 데이터를 2차원 배열로 분할하여 멀티프로세싱(병렬처리)\n",
        "    data_split = np.array_split(data, num_cores)\n",
        "    # 코어 수만큼 pool을 생성\n",
        "    pool = mp.Pool(num_cores)\n",
        "    # 나누어진 데이터를 function으로 넘겨서 병렬처리 수행\n",
        "    data = pd.concat(pool.map(\n",
        "        function, iterable = data_split))\n",
        "    pool.close()\n",
        "    # 모두 완료될 때까지 대기\n",
        "    pool.join\n",
        "    return data\n",
        "\n",
        "\n",
        "# loadData()\n",
        "# 불러온 데이터를 반환(코드 구현 시 활용하고 나중에는 제거할 메서드)\n",
        "  def loadData(self):\n",
        "    return self.cs_data, self.apy_itm_hist_data"
      ],
      "metadata": {
        "id": "t77GBsoeqggs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91e1ccbf-41a3-47fb-b1a5-b6070ee5132d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DataInstance = LoadData(\n",
        "    cs_data_path = \"/content/drive/MyDrive/AfterLearnerProject/DataArchive/cs_data.csv\",\n",
        "    apy_itm_hist_path = \"/content/drive/MyDrive/AfterLearnerProject/DataArchive/apy_itm_hist.csv\",\n",
        ")\n",
        "  # [참고] 경로 너무 길어지니까 겹치는 경로는 os.path.join 활용하여 반복 줄일 수 있음"
      ],
      "metadata": {
        "id": "4GAnB6CEqgdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "consumer_data, apply_item_histogram = DataInstance.loadData()\n",
        "  # cs_data, apy_item_hist 데이터\n",
        "\n",
        "# consumer_merge_data = pd.concat(consumer_data)\n",
        "  # [참고] 텍스트 파일로 저장해도 1.23GB 용량은 줄지 않는바 수행하지 않음\n",
        "  # cs_merge_data.to_csv(\"/content/drive/MyDrive/AfterLearnerProject/DataArchive/cs_data.txt\", index = False)\n",
        "\n",
        "# _, column_length = consumer_merge_data.shape\n",
        "\n",
        "# 총 552개 컬럼(dtypes: float64(325), int64(2), object(195))으로\n",
        "# 컬럼별 타입 및 결측값 확인 반복문 수행 필요\n",
        "\n",
        "# for index in range(0, column_length, 50):\n",
        "   # consumer_merge_data.iloc[:, index : index + 50].info()\n",
        "\n",
        "# msno.bar(consumer_merge_data)\n",
        "  # [참고] 데이터 상세상 0과 결측(NULL)의 구분이 없다는 점에서\n",
        "  # 함부로 결측값을 예측모델로 대체하면 안됨"
      ],
      "metadata": {
        "id": "8kKogFcRqgXM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c50661de-e28b-4c99-ac61-7e09218f7ede"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GetStockCodeData():\n",
        "\n",
        "  def __init__(self,\n",
        "               KOR_SECTOR = None):\n",
        "    self.KOR_SECTOR = KOR_SECTOR\n",
        "\n",
        "\n",
        "  def getStockCode(self, date, market):\n",
        "\n",
        "    stock_list = pd.DataFrame(\n",
        "        {\"종목코드\": stock.get_market_ticker_list(date, market = market)})\n",
        "\n",
        "    stock_list[\"종목명\"] = stock_list[\"종목코드\"].map(lambda x: stock.get_market_ticker_name(x))\n",
        "    # https://github.com/financedata-org/FinanceDataReader/blob/develop/krx/data.py\n",
        "    # fdr_data = fdr.StockListing(\"KRX\")\n",
        "    # stock_list[\"업종\"] = stock_list[\"종목명\"].map(lambda x: fdr_data[fdr_data[\"Name\"] == x][\"Sector\"].iloc[0])\n",
        "    return stock_list\n",
        "\n",
        "\n",
        "  def getStockList(self, base_date):\n",
        "\n",
        "    self.KOSPI_TICKER = self.getStockCode(date = base_date, market = \"KOSPI\")\n",
        "    self.KOSDAQ_TICKER = self.getStockCode(date = base_date, market = \"KOSDAQ\")\n",
        "\n",
        "\n",
        "  def getStockSector(self, sector_code_list: List):\n",
        "\n",
        "    DATA_SECTOR: List = []\n",
        "    for sector_code in sector_code_list:\n",
        "        URL = f'''https://www.wiseindex.com/Index/GetIndexComponets?ceil_yn=0&dt=20230712&sec_cd={ sector_code }'''\n",
        "        DATA = requests.get(URL).json()\n",
        "        DATA_JSON = pd.json_normalize(DATA[\"list\"])\n",
        "        DATA_SECTOR.append(DATA_JSON)\n",
        "        time.sleep(2)\n",
        "    KOR_SECTOR = pd.concat(DATA_SECTOR, axis = 0)\n",
        "    KOR_SECTOR.rename(columns = {\"CMP_CD\": \"TICKER\"}, inplace = True)\n",
        "    self.KOR_SECTOR = KOR_SECTOR[[\"TICKER\", \"SEC_NM_KOR\"]]\n",
        "\n",
        "    # sector_code_list = [\"G10\",\"G15\",\"G20\",\"G25\", \"G30\", \"G35\", \"G40\", \"G45\",\"G50\", \"G55\"]\n",
        "\n",
        "\n",
        "  def getFundamental(self, base_date: str):\n",
        "\n",
        "    KOSPI_FUNDAMENTAL = stock.get_market_fundamental_by_ticker(\n",
        "        date = base_date, market = \"KOSPI\")\n",
        "    KOSPI_FUNDAMENTAL[\"종목코드\"] = KOSPI_FUNDAMENTAL.index\n",
        "    KOSPI_FUNDAMENTAL.reset_index(drop = True, inplace = True)\n",
        "    self.KOSPI_TICKER = pd.merge(\n",
        "        self.KOSPI_TICKER, KOSPI_FUNDAMENTAL,\n",
        "        left_on = \"종목코드\", right_on = \"종목코드\", how = \"outer\")\n",
        "    self.KOSPI_TICKER = pd.merge(\n",
        "        self.KOSPI_TICKER, self.KOR_SECTOR,\n",
        "        left_on = \"종목코드\", right_on = \"TICKER\", how = \"left\")\n",
        "\n",
        "    KOSDAQ_FUNDAMENTAL = stock.get_market_fundamental_by_ticker(\n",
        "        date = base_date, market = \"KOSDAQ\")\n",
        "    KOSDAQ_FUNDAMENTAL[\"종목코드\"] = KOSDAQ_FUNDAMENTAL.index\n",
        "    KOSDAQ_FUNDAMENTAL.reset_index(drop = True, inplace = True)\n",
        "    self.KOSDAQ_TICKER = pd.merge(\n",
        "        self.KOSDAQ_TICKER, KOSDAQ_FUNDAMENTAL,\n",
        "        left_on = \"종목코드\", right_on = \"종목코드\", how = \"outer\")\n",
        "    self.KOSDAQ_TICKER = pd.merge(\n",
        "        self.KOSDAQ_TICKER, self.KOR_SECTOR,\n",
        "        left_on = \"종목코드\", right_on = \"TICKER\", how = \"left\")\n",
        "\n",
        "    return self.KOSPI_TICKER, self.KOSDAQ_TICKER\n"
      ],
      "metadata": {
        "id": "064t-23qlTo0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02f04e4d-892f-4e3e-bfef-5184b23a4bed"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Indicator = GetStockCodeData()\n",
        "# STOCK_CODE_LIST = Indicator.getStockCode()\n",
        "Indicator.getStockList(base_date = \"2023-03-31\")\n",
        "Indicator.getStockSector(sector_code_list = [\"G10\",\"G15\",\"G20\",\"G25\", \"G30\", \"G35\", \"G40\", \"G45\",\"G50\", \"G55\"])\n",
        "KOSPI_DATA, KOSDAQ_DATA = Indicator.getFundamental(base_date = \"2023-03-31\")"
      ],
      "metadata": {
        "id": "fnOeIk9mls47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e065c7e1-f265-4600-a521-b033604d0611"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "STOCK_LIST = pd.concat(\n",
        "    [ KOSPI_DATA, KOSDAQ_DATA ],\n",
        "    axis = 0, ignore_index = True)"
      ],
      "metadata": {
        "id": "vSSuywx-ls1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 특정 기간 동안의 주식 매수액 1(2, 3)위 종목번호\n",
        "\n",
        "```\n",
        "CS_BUY_M2_3 = pd.DataFrame()\n",
        "CS_BUY_M3_1 = pd.DataFrame()\n",
        "CS_BUY_M4_2 = pd.DataFrame()\n",
        "\n",
        "for i in range(len(consumer_data)):\n",
        "  CS_BUY_M2_3 = pd.concat(\n",
        "      [ CS_BUY_M2_3, consumer_data[i].loc[:, [\"BUY1_ITM_M2_3\", \"BUY2_ITM_M2_3\", \"BUY3_ITM_M2_3\"]] ]).dropna()\n",
        "  CS_BUY_M3_1 = pd.concat(\n",
        "      [ CS_BUY_M3_1, consumer_data[i].loc[:, [\"BUY1_ITM_M3_1\", \"BUY2_ITM_M3_1\", \"BUY3_ITM_M3_1\"]] ]).dropna()\n",
        "  CS_BUY_M4_2 = pd.concat(\n",
        "      [ CS_BUY_M4_2, consumer_data[i].loc[:, [\"BUY1_ITM_M4_2\", \"BUY2_ITM_M4_2\", \"BUY3_ITM_M4_2\"]] ]).dropna()\n",
        "\n",
        "CS_BUY_M2_3[\"CONSUMER_ID\"] = CS_BUY_M2_3.index\n",
        "CS_BUY_M3_1[\"CONSUMER_ID\"] = CS_BUY_M3_1.index\n",
        "CS_BUY_M4_2[\"CONSUMER_ID\"] = CS_BUY_M4_2.index\n",
        "```\n",
        "\n",
        "* 특정 기간 동안의 주식 매도액 1(2, 3)위\n",
        "\n",
        "```\n",
        "CS_SELL_M2_3 = pd.DataFrame()\n",
        "CS_SELL_M3_1 = pd.DataFrame()\n",
        "CS_SELL_M4_2 = pd.DataFrame()\n",
        "\n",
        "for i in range(len(consumer_data)):\n",
        "  CS_SELL_M2_3 = pd.concat(\n",
        "      [ CS_SELL_M2_3, consumer_data[i].loc[:, [\"SEL1_ITM_M2_3\", \"SEL2_ITM_M2_3\", \"SEL3_ITM_M2_3\"]] ]).dropna()\n",
        "  CS_SELL_M3_1 = pd.concat(\n",
        "      [ CS_SELL_M3_1, consumer_data[i].loc[:, [\"SEL1_ITM_M3_1\", \"SEL2_ITM_M3_1\", \"SEL3_ITM_M3_1\"]] ]).dropna()\n",
        "  CS_SELL_M4_2 = pd.concat(\n",
        "      [ CS_SELL_M4_2, consumer_data[i].loc[:, [\"SEL1_ITM_M4_2\", \"SEL2_ITM_M4_2\", \"SEL3_ITM_M4_2\"]] ]).dropna()\n",
        "# Counter(CS_SELL_M2_3[\"SEL1_ITM_M2_3\"])\n",
        "\n",
        "CS_SELL_M2_3[\"CONSUMER_ID\"] = CS_SELL_M2_3.index\n",
        "CS_SELL_M3_1[\"CONSUMER_ID\"] = CS_SELL_M3_1.index\n",
        "CS_SELL_M4_2[\"CONSUMER_ID\"] = CS_SELL_M4_2.index\n",
        "```"
      ],
      "metadata": {
        "id": "gF_0OrGYme65"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "___"
      ],
      "metadata": {
        "id": "Upd7uLS6mvzy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.동일한 시기에 투자심리에 영향을 받는 투자자들은 체계적인 투자패턴을 보여야 한다는 가정**\n",
        "\n",
        "1) 특정 시점의 투자심리지수 외 행동패턴 데이터가 존재하는 고객 추출\n",
        "\n",
        "2) 클러스터 생성\n",
        "\n",
        "3) 클러스터별 고객 표본집단을 가지고 투자패턴 / 행태에 통계적으로 유의적인 차이가 있는지 가설검정"
      ],
      "metadata": {
        "id": "oTOfkRVMXOKC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qjN8MtxOSiYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "STNOQkssSiV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ghSVM4ivSiQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cAmOX2m5SiNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P-FeDyp0SiM4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}